import os
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from io import BytesIO
from docx import Document
import google.generativeai as genai
from tensorflow.keras.models import load_model

# ---------- Configuration Gemini ----------
api_key = st.secrets["GEMINI_API_KEY"]
if not api_key:
    st.error("Cl√© API Gemini manquante dans secrets.toml")
    st.stop()

genai.configure(api_key=api_key)

generation_config = {
    "temperature": 1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8192,
    "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    generation_config=generation_config,
)

# ---------- Charger le mod√®le CNN ----------
MODEL_PATH = "CNN 1D model.h5"
try:
    cnn_model = load_model(MODEL_PATH)
except Exception as e:
    st.error(f"Erreur de chargement du mod√®le : {e}")
    st.stop()

# ---------- Dictionnaire des classes ----------
classes = {
    0: ("Normal (N)", "Battement cardiaque normal (rythme sinusal normal)."),
    1: ("Extrasystole ventriculaire (VEB / PVC)", "Battement pr√©matur√© provenant des ventricules."),
    2: ("Battements supraventriculaires (SVEB)", "Battements pr√©matur√©s provenant des oreillettes."),
    3: ("Fusion de battements (F)", "Fusion entre un battement normal et un VEB."),
    4: ("Battements inconnus (Q)", "Battements non classifi√©s dans les cat√©gories pr√©c√©dentes."),
}

# ---------- Fonctions ----------
def preprocess_ecg(csv_file):
    df = pd.read_csv(csv_file, header=None)
    if df.shape[1] != 188:
        st.error("‚ö†Ô∏è Le fichier CSV doit contenir exactement 188 colonnes.")
        return None
    ecg_signal = df.iloc[:, :-1].values
    ecg_data = np.expand_dims(ecg_signal, axis=-1)
    return ecg_data

def plot_ecg_signal(signal, title="üìà Signal ECG (1er √©chantillon)"):
    fig, ax = plt.subplots(figsize=(10, 3))
    ax.plot(signal, color='dodgerblue')
    ax.set_title(title)
    ax.set_xlabel("Temps (√©chantillons)")
    ax.set_ylabel("Amplitude")
    ax.grid(True)
    st.pyplot(fig)

# Nouveau : r√©ponse dans la langue de la question
def get_bot_response(user_input):
    prompt = f"""
You are a professional, empathetic, and kind-hearted cardiologist.

Your role is to help users understand:

Electrocardiograms (ECGs)

Heart diseases

Cardiovascular health

Heart-related treatments

Always reply in the same language used in the user's question.

If the question is not related to cardiology, politely respond (in the same language):
"I specialize in cardiology. I'm here to help you only with matters related to the heart and cardiovascular health."

Use a clear, human, reassuring, and professional tone.
"""

    chat_session = model.start_chat(history=[
        {"role": "user", "parts": [prompt]}
    ])
    response = chat_session.send_message(user_input)
    return response.text

def generate_word_report(class_name, class_description, prediction):
    doc = Document()
    doc.add_heading("Rapport d‚ÄôAnalyse ECG", level=1)

    doc.add_heading("R√©sultat Principal :", level=2)
    doc.add_paragraph(f"Classe pr√©dite : {class_name}")
    doc.add_paragraph(f"Description : {class_description}")

    doc.add_heading("D√©tail des probabilit√©s :", level=2)
    for idx, prob in enumerate(prediction[0]):
        name, desc = classes[idx]
        doc.add_paragraph(f"{name} ({desc}) : {prob:.4f}")

    file_stream = BytesIO()
    doc.save(file_stream)
    file_stream.seek(0)
    return file_stream

# ---------- Application principale ----------
def main():
    st.set_page_config(page_title="Assistant M√©dical Cardiaque", page_icon="ü´Ä")
    st.title("ü´Ä Assistant M√©dical Cardiaque")

    st.header("üìÇ T√©l√©versez un fichier ECG (CSV)")
    uploaded_file = st.file_uploader("Choisissez un fichier .csv", type=["csv"])

    if uploaded_file is not None:
        st.success("‚úÖ Fichier upload√© avec succ√®s !")
        ecg_input = preprocess_ecg(uploaded_file)

        if ecg_input is not None:
            st.subheader("üìä Signal ECG d√©tect√©")
            plot_ecg_signal(ecg_input[0].squeeze())

            prediction = cnn_model.predict(ecg_input)
            predicted_class_idx = np.argmax(prediction, axis=1)[0]
            class_name, class_description = classes[predicted_class_idx]

            st.subheader("üîç R√©sultat de l‚Äôanalyse automatique :")
            st.success(f"Classe pr√©dite : **{class_name}**")
            st.markdown(f"üìù *{class_description}*")

            st.subheader("üìä D√©tail des probabilit√©s par classe :")
            for idx, prob in enumerate(prediction[0]):
                name, desc = classes[idx]
                st.markdown(f"**{name}** ‚Äî {desc} : **{prob:.4f}**")
                st.progress(float(prob))

            st.subheader("üì• T√©l√©charger le rapport m√©dical (.docx)")
            word_file = generate_word_report(class_name, class_description, prediction)
            st.download_button(
                label="üìÑ T√©l√©charger le rapport Word",
                data=word_file,
                file_name="rapport_ecg.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )

    # Chat IA
    st.header("üí¨ Posez une question √† l‚ÄôIA cardiologue")
    st.markdown("ü©∫ *Je suis un assistant m√©dical sp√©cialis√© en **cardiologie**. Posez-moi vos questions sur le c≈ìur, l‚ÄôECG, ou les traitements cardiaques.*")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    user_input = st.chat_input("Posez une question sur l‚ÄôECG, les anomalies, etc.")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.spinner("R√©flexion en cours..."):
            bot_response = get_bot_response(user_input)

        st.session_state.messages.append({"role": "assistant", "content": bot_response})
        with st.chat_message("assistant"):
            st.markdown(bot_response)

if __name__ == "__main__":
    main()
